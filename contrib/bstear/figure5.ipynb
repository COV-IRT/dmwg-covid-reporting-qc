{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "out = '/path/to/save/public_tracker_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmwr = ['12-16_aug', '17-21', '22-26',  '27-31']  \n",
    "mmwr_wkly = range(12,31)\n",
    "cols = ['12-16_may','12-16_aug', '17-21', '22-26', '27-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = pd.read_csv('~/nyt_aug19.csv',sep=',',parse_dates=['date'])\n",
    "\n",
    "nyt.index = nyt['date']\n",
    "nyt.drop(['cases','date'],axis=1,inplace=True)\n",
    "nyt.sort_values(['state','date'],inplace=True)\n",
    "\n",
    "nyt_all = pd.DataFrame()\n",
    "\n",
    "for i in np.unique(nyt['state']):\n",
    "    nyt_agg= list()\n",
    "    d = nyt[nyt['state']==i]['deaths']\n",
    "    if '2020-02-01' in nyt[nyt['state']==i]['deaths'].index:\n",
    "        nyt_agg.append(d['2020-04-25'] - d['2020-03-21'])\n",
    "    else:\n",
    "        nyt_agg.append(d['2020-04-25'])\n",
    "        \n",
    "    nyt_agg.append(d['2020-05-30'] - d['2020-04-25'])\n",
    "    nyt_agg.append(d['2020-07-04'] - d['2020-05-30'])\n",
    "    nyt_agg.append(d['2020-08-08'] - d['2020-07-04'])    \n",
    "    nyt_all[i]  =  nyt_agg\n",
    "\n",
    "nyt_df =  pd.DataFrame(nyt_all).drop(['Northern Mariana Islands','Puerto Rico','Virgin Islands','Guam'],axis=1).T\n",
    "\n",
    "nyt_df.loc['AAusa'] = nyt_df.sum()  #  add all US\n",
    "nyt_df.sort_index(inplace=True)\n",
    "\n",
    "nyt_df.columns = mmwr\n",
    "nyt_df['12-16_may'] = nyt_df['12-16_aug']  # add may col\n",
    "\n",
    "nyt_df = nyt_df[cols]\n",
    "nyt_df.to_csv(out+f'NYT_5MMWRagg.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU/CSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu = pd.read_csv('~/18AugCSSEtime_series_covid19_deaths_US.csv',sep=',')\n",
    "\n",
    "jhu.drop(['UID','iso2','iso3','code3','FIPS','Admin2','Country_Region','Lat','Long_','Combined_Key','Population'],inplace=True,axis=1)\n",
    "\n",
    "jhu_all = pd.DataFrame()\n",
    "\n",
    "for i in  np.unique(jhu['Province_State']): \n",
    "    jhu_agg = list()\n",
    "    ss = jhu[jhu['Province_State']==i].sum()\n",
    "    jhu_agg.append(ss['4/25/20'] - ss['3/21/20'])\n",
    "    jhu_agg.append(ss['5/30/20'] - ss['4/25/20'])\n",
    "    jhu_agg.append(ss['7/4/20'] - ss['5/30/20'])\n",
    "    jhu_agg.append(ss['8/8/20'] - ss['7/4/20'])\n",
    "    jhu_all[i]  = jhu_agg\n",
    "    \n",
    "jhu_df =  pd.DataFrame(jhu_all).drop(['American Samoa','Grand Princess', 'Northern Mariana Islands',\n",
    "                                      'Puerto Rico','Virgin Islands','Guam','Diamond Princess'],axis=1).T\n",
    "\n",
    "jhu_df.loc['AAusa'] = jhu_df.sum()  #  add all US\n",
    "jhu_df.sort_index(inplace=True)\n",
    "\n",
    "jhu_df.columns = mmwr\n",
    "jhu_df['12-16_may'] = jhu_df['12-16_aug']  # add may col\n",
    "\n",
    "jhu_df = jhu_df[cols]\n",
    "\n",
    "jhu_df.to_csv(out+f'JHU_5MMWRagg.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USAFacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "usafacts = pd.read_csv('~/18Augcovid_deaths_usafacts.csv',sep=',')\n",
    "usa_all = pd.DataFrame()\n",
    "\n",
    "for i in np.unique(usafacts['State']):\n",
    "    usa_agg = list()\n",
    "    ss = usafacts[usafacts['State']==i].iloc[:,4:].sum()\n",
    "    usa_agg.append(ss['4/25/20'] - ss['3/21/20'])\n",
    "    usa_agg.append(ss['5/30/20'] - ss['4/25/20'])\n",
    "    usa_agg.append(ss['7/4/20'] - ss['5/30/20'])\n",
    "    usa_agg.append(ss['8/8/20'] - ss['7/4/20'])\n",
    "    usa_all[i] = usa_agg\n",
    "    \n",
    "usa_df =  pd.DataFrame(usa_all).T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Atlantic Covid Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl = pd.read_csv('~/18AugVTrakStatesdaily.csv',parse_dates=['date'],sep=',')\n",
    "\n",
    "atl[['date','state','death','deathConfirmed','deathProbable']].head(5)\n",
    "atl.index = atl['date']\n",
    "\n",
    "atl_all = pd.DataFrame()\n",
    "\n",
    "for i in np.unique(atl['state']):  # ['AL']:\n",
    "    atl_agg = list()\n",
    "    ss = atl[atl['state']==i]['death']\n",
    "    if len(ss['20200201']):\n",
    "        atl_agg.append(ss['20200425'].item() - ss['20200321'].item())\n",
    "    else:\n",
    "        atl_agg.append(ss['20200425'].item())\n",
    "    atl_agg.append(ss['20200530'].item() - ss['20200425'].item())\n",
    "    atl_agg.append(ss['20200704'].item() - ss['20200530'].item())\n",
    "    atl_agg.append(ss['20200808'].item() - ss['20200704'].item())\n",
    "    atl_all[i] = atl_agg\n",
    "\n",
    "atl_df =  pd.DataFrame(atl_all).drop(['AS', 'PR', 'VI','GU','MP'],axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "inv_map = {v: k for k, v in us_state_abbrev.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert state abbreviations to state names for usafacts and atlantic datasets indices\n",
    "new_cols = []\n",
    "for i in usa_df.index.to_list():\n",
    "    new_cols.append(inv_map[i])\n",
    "    \n",
    "usa_df.index = new_cols\n",
    "atl_df.index = new_cols\n",
    "\n",
    "atl_df.sort_index(inplace=True)\n",
    "usa_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all US and may col for USAFacts\n",
    "usa_df.loc['AAusa'] = usa_df.sum()  #  add all US\n",
    "usa_df.sort_index(inplace=True)\n",
    "\n",
    "usa_df.columns = mmwr\n",
    "usa_df['12-16_may'] = usa_df['12-16_aug']  # add may col\n",
    "usa_df = usa_df[cols]\n",
    "\n",
    "# Add all US and may col for The Atlantic\n",
    "atl_df.loc['AAusa'] = atl_df.sum()  #  add all US\n",
    "atl_df.sort_index(inplace=True)\n",
    "\n",
    "atl_df.columns = mmwr\n",
    "atl_df['12-16_may'] = atl_df['12-16_aug']  # add may col\n",
    "atl_df = atl_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(usa_df.index  == atl_df.index)\n",
    "assert np.all(jhu_df.index == nyt_df.index)\n",
    "assert np.all(jhu_df.index == usa_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl_df.to_csv(out+f'Atlantic_5MMWRagg.csv',sep=',')\n",
    "usa_df.to_csv(out+f'USAFacts_5MMWRagg.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average of public trackers\n",
    "tracker_mean = (jhu_df + nyt_df + usa_df + atl_df)/4\n",
    "tracker_mean.to_csv(out+'public_trackers_mean.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDC May 21 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_may = pd.read_csv('~/21MayI9C1AbnWeekly_Select_Causes_Sept_19-20.csv',parse_dates=['Week Ending Date'],sep=',')  \n",
    "cdc_may.index = cdc_may['Week Ending Date']\n",
    "\n",
    "cdc_may_all = pd.DataFrame()\n",
    "for i in np.unique(cdc_may['Jurisdiction of Occurrence']):\n",
    "    cdc_may_agg=list()\n",
    "    ss= cdc_may[cdc_may['Jurisdiction of Occurrence'] == i]['COVID-19 (U071, Underlying Cause of Death)']\n",
    "    cdc_may_agg.append(ss['2020-03-21':'2020-04-25'].sum())\n",
    "    cdc_may_all[i] = cdc_may_agg\n",
    "\n",
    "    \n",
    "cdc_may_all['New York'] = cdc_may_all['New York'] + cdc_may_all['New York City']\n",
    "cdc_may_all.drop(['New York City'],axis=1,inplace=True)\n",
    "\n",
    "cdc_may_df =  pd.DataFrame(cdc_may_all).drop(['United States','Puerto Rico'],axis=1).T\n",
    "cdc_may_df.columns = ['12-16_may']\n",
    "\n",
    "cdc_may_df.loc['AAusa'] = cdc_may_df.sum()\n",
    "cdc_may_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDC August dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IN =  '~/26AugustI9C1AbnWeekly_Select_Causes__2019-2020.csv'\n",
    "df = pd.read_csv(PATH_IN,sep=',',parse_dates=['Week Ending Date'])\n",
    "df.index = df['Week Ending Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_aug_all = pd.DataFrame()\n",
    "for i in np.unique(df['Jurisdiction of Occurrence']):\n",
    "    cdc_aug_agg=list()\n",
    "    ss= df[df['Jurisdiction of Occurrence'] == i]['COVID-19 (U071, Underlying Cause of Death)']\n",
    "    cdc_aug_agg.append(ss['2020-03-21':'2020-04-25'].sum())\n",
    "    cdc_aug_agg.append(ss['2020-04-26':'2020-05-30'].sum())\n",
    "    cdc_aug_agg.append(ss['2020-05-31':'2020-07-04'].sum())\n",
    "    cdc_aug_agg.append(ss['2020-07-05':'2020-08-08'].sum())\n",
    "    cdc_aug_all[i] = cdc_aug_agg\n",
    "    \n",
    "cdc_aug_all['New York'] = cdc_aug_all['New York'] + cdc_aug_all['New York City']\n",
    "cdc_aug_all.drop(['New York City'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_aug_df =  pd.DataFrame(cdc_aug_all).drop(['United States','Puerto Rico'],axis=1).T\n",
    "cdc_aug_df.columns = mmwr\n",
    "\n",
    "cdc_aug_df.loc['AAusa'] = cdc_aug_df.sum()\n",
    "cdc_aug_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(cdc_aug_df.index == tracker_mean.index)\n",
    "assert np.all(cdc_aug_df.index == cdc_may_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_data = pd.concat([cdc_may_df,cdc_aug_df],axis=1)\n",
    "cdc_data.to_csv(out+'CDC_5MMWR_agg.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = cdc_data/tracker_mean\n",
    "ratios.to_csv(out+'ratios_for_heatmap.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Compute Coefficient of Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find weekly death counts for all 4 public trackers for each state\n",
    "\n",
    "\n",
    "##############################################\n",
    "###############   NYT   ######################\n",
    "nyt_all_WK = pd.DataFrame()\n",
    "\n",
    "for i in np.unique(nyt['state']): \n",
    "    \n",
    "    nyt_agg= list()\n",
    "    ss = nyt[nyt['state']==i]['deaths']\n",
    "    \n",
    "    if not (('2020-03-21' in nyt[nyt['state']==i]['deaths'].index) or ('2020-03-28' in nyt[nyt['state']==i]['deaths'].index)):\n",
    "        nyt_agg.append(0)\n",
    "    elif (not ('2020-03-21' in nyt[nyt['state']==i]['deaths'].index)) and ('2020-03-28' in nyt[nyt['state']==i]['deaths'].index):\n",
    "        nyt_agg.append(ss['2020-03-28'])\n",
    "    elif ('2020-03-21' in nyt[nyt['state']==i]['deaths'].index) and ('2020-03-28' in nyt[nyt['state']==i]['deaths'].index):\n",
    "        nyt_agg.append(ss['2020-03-28'] - ss['2020-03-21'])\n",
    "\n",
    "    nyt_agg.append(ss['2020-04-04'] - ss['2020-03-29'])\n",
    "    nyt_agg.append(ss['2020-04-11'] - ss['2020-04-05'])\n",
    "    nyt_agg.append(ss['2020-04-18'] - ss['2020-04-12'])\n",
    "    nyt_agg.append(ss['2020-04-25'] - ss['2020-04-19'])\n",
    "    nyt_agg.append(ss['2020-05-02'] - ss['2020-04-26'])\n",
    "    nyt_agg.append(ss['2020-05-09'] - ss['2020-05-03'])\n",
    "    nyt_agg.append(ss['2020-05-16'] - ss['2020-05-10'])\n",
    "    nyt_agg.append(ss['2020-05-23'] - ss['2020-05-17'])\n",
    "    nyt_agg.append(ss['2020-05-30'] - ss['2020-05-24'])\n",
    "    nyt_agg.append(ss['2020-06-06'] - ss['2020-05-31'])\n",
    "    nyt_agg.append(ss['2020-06-13'] - ss['2020-06-07'])\n",
    "    nyt_agg.append(ss['2020-06-20'] - ss['2020-06-14'])\n",
    "    nyt_agg.append(ss['2020-06-27'] - ss['2020-06-21'])\n",
    "    nyt_agg.append(ss['2020-07-04'] - ss['2020-06-28'])\n",
    "    nyt_agg.append(ss['2020-07-11'] - ss['2020-07-05'])\n",
    "    nyt_agg.append(ss['2020-07-18'] - ss['2020-07-12'])\n",
    "    nyt_agg.append(ss['2020-07-25'] - ss['2020-07-19'])\n",
    "    nyt_agg.append(ss['2020-08-01'] - ss['2020-07-26'])\n",
    "    nyt_all_WK[i]  =  nyt_agg\n",
    "\n",
    "nyt_df =  pd.DataFrame(nyt_all_WK).drop(['Northern Mariana Islands','Puerto Rico','Virgin Islands','Guam'],axis=1).T\n",
    "nyt_df.loc['AAusa'] = nyt_df.sum()  #  add all US\n",
    "nyt_df.sort_index(inplace=True)\n",
    "\n",
    "nyt_df.columns = mmwr_wkly\n",
    "\n",
    "\n",
    "##############################################\n",
    "###############   JHU   ######################\n",
    "jhu_all_WK = pd.DataFrame()\n",
    "\n",
    "for i in  np.unique(jhu['Province_State']): \n",
    "    jhu_agg = list()\n",
    "    ss = jhu[jhu['Province_State']==i].sum()\n",
    "    jhu_agg.append(ss['3/28/20'] - ss['3/21/20'])\n",
    "    jhu_agg.append(ss['4/4/20'] - ss['3/29/20'])\n",
    "    jhu_agg.append(ss['4/11/20'] - ss['4/5/20'])\n",
    "    jhu_agg.append(ss['4/18/20'] - ss['4/12/20'])\n",
    "    jhu_agg.append(ss['4/25/20'] - ss['4/19/20'])\n",
    "    jhu_agg.append(ss['5/2/20'] - ss['4/26/20'])\n",
    "    jhu_agg.append(ss['5/9/20'] - ss['5/3/20'])\n",
    "    jhu_agg.append(ss['5/16/20'] - ss['5/10/20'])\n",
    "    jhu_agg.append(ss['5/23/20'] - ss['5/17/20'])\n",
    "    jhu_agg.append(ss['5/30/20'] - ss['5/24/20'])\n",
    "    jhu_agg.append(ss['6/6/20'] - ss['5/31/20'])\n",
    "    jhu_agg.append(ss['6/13/20'] - ss['6/7/20'])\n",
    "    jhu_agg.append(ss['6/20/20'] - ss['6/14/20'])\n",
    "    jhu_agg.append(ss['6/27/20'] - ss['6/21/20'])\n",
    "    jhu_agg.append(ss['7/4/20'] - ss['6/28/20'])\n",
    "    jhu_agg.append(ss['7/11/20'] - ss['7/5/20'])\n",
    "    jhu_agg.append(ss['7/18/20'] - ss['7/12/20'])\n",
    "    jhu_agg.append(ss['7/25/20'] - ss['7/19/20'])\n",
    "    jhu_agg.append(ss['8/1/20'] - ss['7/26/20'])\n",
    "    jhu_all_WK[i]  = jhu_agg\n",
    "    \n",
    "jhu_df =  pd.DataFrame(jhu_all_WK).drop(['American Samoa','Grand Princess', 'Northern Mariana Islands',\n",
    "                                      'Puerto Rico','Virgin Islands','Guam','Diamond Princess'],axis=1).T\n",
    "\n",
    "jhu_df.loc['AAusa'] = jhu_df.sum()  #  add all US\n",
    "jhu_df.sort_index(inplace=True)\n",
    "jhu_df.columns = mmwr_wkly\n",
    "\n",
    "\n",
    "##############################################\n",
    "#############   Atlantic   ###################\n",
    "\n",
    "atl_all_WK = pd.DataFrame()\n",
    "\n",
    "for i in np.unique(atl['state']):  \n",
    "    atl_agg = list()\n",
    "    ss = atl[atl['state']==i]['death']\n",
    "    \n",
    "    if (len(ss['20200321']) == 1) and (len(ss['20200328']) == 1):\n",
    "        atl_agg.append(ss['20200328'].item() - ss['20200321'].item()) \n",
    "\n",
    "    elif len(ss['20200321']) == 0 and len(ss['20200328']) == 1:\n",
    "        atl_agg.append(ss['20200328'].item())\n",
    "    elif len(ss['20200321']) == 0 and len(ss['20200328']) == 0:\n",
    "            atl_agg.append(0)\n",
    "    atl_agg.append(ss['20200404'].item() - ss['20200329'].item())\n",
    "    atl_agg.append(ss['20200411'].item() - ss['20200405'].item())\n",
    "    atl_agg.append(ss['20200418'].item() - ss['20200412'].item())\n",
    "    atl_agg.append(ss['20200425'].item() - ss['20200419'].item())\n",
    "    atl_agg.append(ss['20200502'].item() - ss['20200426'].item())\n",
    "    atl_agg.append(ss['20200509'].item() - ss['20200503'].item())\n",
    "    atl_agg.append(ss['20200516'].item() - ss['20200510'].item())\n",
    "    atl_agg.append(ss['20200523'].item() - ss['20200517'].item())\n",
    "    atl_agg.append(ss['20200530'].item() - ss['20200524'].item())\n",
    "    atl_agg.append(ss['20200606'].item() - ss['20200531'].item())\n",
    "    atl_agg.append(ss['20200613'].item() - ss['20200607'].item())\n",
    "    atl_agg.append(ss['20200620'].item() - ss['20200614'].item())\n",
    "    atl_agg.append(ss['20200627'].item() - ss['20200621'].item())\n",
    "    atl_agg.append(ss['20200704'].item() - ss['20200628'].item())\n",
    "    atl_agg.append(ss['20200711'].item() - ss['20200705'].item())\n",
    "    atl_agg.append(ss['20200718'].item() - ss['20200712'].item())\n",
    "    atl_agg.append(ss['20200725'].item() - ss['20200719'].item())\n",
    "    atl_agg.append(ss['20200801'].item() - ss['20200726'].item())\n",
    "    atl_all_WK[i]  = atl_agg\n",
    "\n",
    "atl_df =  pd.DataFrame(atl_all_WK).drop(['AS', 'PR', 'VI','GU','MP'],axis=1).T\n",
    "\n",
    "\n",
    "\n",
    "##############################################\n",
    "##############  USAfacts   ###################\n",
    "usa_all_WK = pd.DataFrame()\n",
    "\n",
    "for i in np.unique(usafacts['State']):\n",
    "    usa_agg = list()\n",
    "    ss = usafacts[usafacts['State']==i].iloc[:,4:].sum()\n",
    "    usa_agg.append(ss['3/28/20'] - ss['3/21/20'])\n",
    "    usa_agg.append(ss['4/4/20'] - ss['3/29/20'])\n",
    "    usa_agg.append(ss['4/11/20'] - ss['4/5/20'])\n",
    "    usa_agg.append(ss['4/18/20'] - ss['4/12/20'])\n",
    "    usa_agg.append(ss['4/25/20'] - ss['4/19/20'])\n",
    "    usa_agg.append(ss['5/2/20'] - ss['4/26/20'])\n",
    "    usa_agg.append(ss['5/9/20'] - ss['5/3/20'])\n",
    "    usa_agg.append(ss['5/16/20'] - ss['5/10/20'])\n",
    "    usa_agg.append(ss['5/23/20'] - ss['5/17/20'])\n",
    "    usa_agg.append(ss['5/30/20'] - ss['5/24/20'])\n",
    "    usa_agg.append(ss['6/6/20'] - ss['5/31/20'])\n",
    "    usa_agg.append(ss['6/13/20'] - ss['6/7/20'])\n",
    "    usa_agg.append(ss['6/20/20'] - ss['6/14/20'])\n",
    "    usa_agg.append(ss['6/27/20'] - ss['6/21/20'])\n",
    "    usa_agg.append(ss['7/4/20'] - ss['6/28/20'])\n",
    "    usa_agg.append(ss['7/11/20'] - ss['7/5/20'])\n",
    "    usa_agg.append(ss['7/18/20'] - ss['7/12/20'])\n",
    "    usa_agg.append(ss['7/25/20'] - ss['7/19/20'])\n",
    "    usa_agg.append(ss['8/1/20'] - ss['7/26/20'])\n",
    "    usa_all_WK[i] = usa_agg\n",
    "    \n",
    "usa_df =  pd.DataFrame(usa_all_WK).T \n",
    "\n",
    "\n",
    "# Convert abbreviations to state names\n",
    "new_cols = []\n",
    "for i in usa_df.index.to_list():\n",
    "    new_cols.append(inv_map[i])\n",
    "    \n",
    "usa_df.index = new_cols\n",
    "atl_df.index = new_cols\n",
    "\n",
    "atl_df.sort_index(inplace=True)\n",
    "usa_df.sort_index(inplace=True)\n",
    "\n",
    "# Add all US and may col for USAFacts and The Alantic\n",
    "usa_df.loc['AAusa'] = usa_df.sum()  #  add all US\n",
    "usa_df.sort_index(inplace=True)\n",
    "usa_df.columns = mmwr_wkly\n",
    "\n",
    "atl_df.loc['AAusa'] = atl_df.sum()  #  add all US\n",
    "atl_df.sort_index(inplace=True)\n",
    "atl_df.columns = mmwr_wkly\n",
    "\n",
    "\n",
    "assert nyt_df.shape == jhu_df.shape\n",
    "assert usa_df.shape == atl_df.shape\n",
    "assert np.all(nyt_df.index == jhu_df.index)\n",
    "assert np.all(usa_df.index == atl_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import variation as coeffvar\n",
    "\n",
    "cov_vec= pd.DataFrame()\n",
    "for i in nyt_df.index: \n",
    "\n",
    "    d = pd.DataFrame([jhu_df.loc[i].values,nyt_df.loc[i].values,atl_df.loc[i].values,\n",
    "            usa_df.loc[i].values],index= ['jhu','nyt','atl','usafacts'])\n",
    "    cov_vec[i] = coeffvar(d)\n",
    "    \n",
    "coeff_vec = cov_vec.replace(np.nan,0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colorado\n",
      "Delaware\n",
      "Idaho\n",
      "Kansas\n",
      "Michigan\n",
      "Missouri\n",
      "Nebraska\n",
      "Nevada\n",
      "New Jersey\n",
      "New York\n",
      "North Dakota\n",
      "Texas\n"
     ]
    }
   ],
   "source": [
    "# compare to US Coeff. Var. (summed) total\n",
    "i = 'AAusa'\n",
    "\n",
    "d = pd.DataFrame([jhu_df.loc[i].values,nyt_df.loc[i].values,atl_df.loc[i].values,\n",
    "            usa_df.loc[i].values],index= ['jhu','nyt','atl','usafacts'])\n",
    "\n",
    "# compute US coeff. var. for entire time period\n",
    "total_US_CoV  = d.sum(axis=1).std() / d.sum(axis=1).mean()\n",
    "\n",
    "\n",
    "for i in nyt_df.index:\n",
    "    if i is not 'AAusa':            # if a state has a higher Coeff. Var. than overall US more than 8 times, \n",
    "        if sum(coeff_vec.loc[i] > 2*total_US_CoV) > 8:  # we consider it to have a high Coeff. Var\n",
    "            print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
